<?xml version="1.0" encoding="UTF-8"?>
<SearchIndexes Version="1.0">
    <Documents>
        <Document ID="4AC9DB1E-6D60-4CA0-91D2-7593DD01FDAD">
            <Title>Past copies</Title>
            <Synopsis>Duplicate important drafts into here.</Synopsis>
        </Document>
        <Document ID="427A32D2-FF76-4EA5-841E-B29A11BB1D81">
            <Title>Methods</Title>
        </Document>
        <Document ID="F2B9C1AF-0725-4D78-AAC2-AAAA06A9A327">
            <Title>Cover letter</Title>
            <Text>[NOTE ANY SPECIAL ISSUE HERE]

Dear Editors:

It was with great interest that I read of the recent [Call for Papers]. We are very pleased to submit to your our paper “&lt;$Projecttitle&gt;.” This paper describes …

In this paper we describe the …

We believe that this paper would represent a unique contribution to the literature …, and thank you for review of this manuscript.

Sincerely,

&lt;Insert signature line here&gt;</Text>
            <Notes>Outline for the Cover Letter:
	1.	An introduction stating the title of the manuscript and the journal to which you are submitting.
	2.	The reason why your study is important and relevant to the journal’s readership or field.
	3.	The question your research answers.
	4.	Your major experimental results and overall findings.
	5.	The most important conclusions that can be drawn from your research.
	6.	A statement that the manuscript has not been published and is not under consideration for publication in any other journal
	7.	A statement that all authors approved the manuscript and its submission to the journal.
	8.	Any other details that will encourage the editor to send your manuscript for review.

Write one or more sentences to address each of these points. You will revise and polish these sentences to complete your cover letter. Detailed instructions on how to write a good cover letter can be found here:
http://www.biosciencewriters.com/Writing-Cover-Letters-for-Scientific-Manuscripts.aspx
</Notes>
        </Document>
        <Document ID="581216D4-F22A-498F-93C3-85A00536F376">
            <Title>Project Notes</Title>
        </Document>
        <Document ID="F7AC1BC1-1F24-42C2-831A-D59F30E36D2E">
            <Title>Templates</Title>
        </Document>
        <Document ID="FFF3B74B-BF7C-45D0-B5A1-47AAF70B72F5">
            <Title>Abstract &amp; keywords</Title>
            <Text>Abstract

I. Algorithm (Network Parameter Outlier, NPO)
1. Shape of biological signals change with time, but algos rarely are designed to handle this.
2. Describe the algo
3. Test the algo
a. Rodent AP and ripples - seizures disrupt phase reac.
b. Human AP, ripples and IIS - look at paired ripples
4. *Signal clusters across scales are hubs
II. Application
1. NeuroVista data and IIS
2. SRC
3. Examples of persistent changes
4. *Necessity of post-seizure sleep
III. Do the main results co-inform?
hubs require sleep? This could be tested!
sleep is about hubs?
sleep forms/allows hubs?
can signals across the brain identify each other?

does sleep fabricate consciousness?
It is interesting that the farther we are from sleep,
the harder consciousness is to maintain.


NB: Please remember that you have documentation in the Analysis section as an .Rmd document.

Objective. Machine learning and classification algorithms are “taught” using methods that differ from those used to teach human students. Machine learning algorithms normally work on an entire data set at once, computing multi-dimensional features and category boundaries (“separatrices”) using iterative optimization algorithms [Duda and Hart] whose computational time increases exponentially with data size. Humans are restricted to lower-dimensional space and sequential, localized time domains seeking repeated, outlier events that are rare compared to lower-amplitude noise events and that conform to expected, “physiological” ranges and frequencies. Despite the advantages of machine learning, visual validation by a trained, human observer remains the “gold standard” for virtually all biological signal processing tasks. In addition, humans are able to adjust categorical boundaries over time if signals show small amounts of variability. Graphical clustering algorithms on temporally bounded data achieve near-linear time performance, suggesting a possible bridge between machine and human clustering methods.

Materials and Methods. We implemented a graphical clustering algorithm using sliding windows of data. Each time-voltage peak was encoded as a vertex connected to other vertices by their correlation coefficient. This removed the need for both thresholding and exponential-time optimization algorithms. Because the signal properties used for making decisions were valid for all biological signals, we used the same algorithm to detect action potentials (AP) from microwires and sharp-wave/ripple (SWR) complexes and interictal spikes (IIS) recorded from macroelectrodes based on the spectral filtering and expected temporal window of signals. (Can you detect SWR without detected IIS, and vice-versa?). Data were obtained from freely-moving rats, patients undergoing intracranial monitoring in the Yale ICU, and patients outside the hospital using an ambulatory EEG system.

Results. The algorithm run-time scaled nearly linearly with data size. It produced similar classification results on test data. The algorithm reproduced several known results, showing that the signals identified by the algorithm were indeed signals. In addition, the ability of the algorithm to adjust to small changes in signal waveforms was shown through a new result. IIS waveforms were observed to change following post-seizure sleep (known as Seizure Related Consolidation, or SRC) and these changes then persisted until the next seizure. 

Discussion. 

Keywords: &lt;$keywords&gt;

Biological signal detection algorithms normally are based on a two-step algorithm: thresholding to reduce noise detections followed by iterative optimization methods (e.g., Maximum Likelihood Estimation) to identify and cluster similar signals. Both thresholding and optimization techniques became popular in the mid-20th century when computational power was limited and data storage was expensive. Thresholding reduced the size of the target dataset, allowing signal-rich data to be stored on expensive hard disks. Computationally complex optimization algorithms became common when sufficient CPU power became affordable to individual researchers, allowing “semi-automated” approaches to signal identification and clustering. Subsequent improvements in technology, however, have reduced both of these barriers, but the continued observance of these constraints has limited algorithm advancement. Readily-available computers can now record and analyze terabytes of data, eliminating the need for threshold-based noise reduction, and parallel processing on computer clusters has given rise to techniques (e.g., bootstrapping) that no longer rely on an assumption of simplified, analytical statistical distributions (e.g., Gaussian distributions). In particular, recent advances in mathematical graph theory have provided graphical clustering algorithms known as “local clustering algorithms” that scale nearly linearly is with the amount of data [Fountoulakis, Gleich and Mahoney, 2018]. These advances, however, have found limited application in biological signal processing.

Biological events often consist of repeated, time-bounded events that share three properties relative to noise events: signals are relatively larger in amplitude, rare relative to noise events, and repeat in shape, at least over short timescale. These properties feature prominently in our determination of whether events identified by detection and clustering algorithms can reasonably be considered “signals”. Heartbeats, muscle contractions (e.g., eye blinks), and neural field and action potentials all consist of a series of temporally-bounded events separated by periods of inactivity. This suggests that, in addition to conventional waveform-based features used in classification algorithms (e.g., peak, energy, principal components), temporally-based features may also be of use; that is, parameters based on events occurring nearby one another in time. This would be particularly beneficial to signals whose waveforms are known to change slightly with time, either due to changes in electrode position (i.e., “drift”) or to underlying neural circuitry (i.e., learning). Temporally local classification would be more capable of tracking such changes than would a temporally-global classification algorithm.

Recent advances in graphical clustering have shown that local clustering algorithms can operate in linear or nearly linear time [Fountoulakis etal, 2018]. Temporally-compact events can be stored in a graph as vertices and linked using correlation coefficients as weights between vertices. Common graphical algorithms can then be used to cluster similar waveforms and then compute network parameters on the resulting network. This clustering has the advantage of finding similarities across the entirety of a given, “correlation window” based on physiological expectations of how long events from the same generator should appear to be similar. Given the assumption that most detected peaks are noise (i.e., signals are rare relative to noise), the resulting clusters can be directly separated into signal and noise [Bower etal, 20xx - patent application]. 

Combining these ideas, we implemented a graph-based clustering algorithm using temporographical properties of biological events in addition to traditional time-voltage characteristics to produce a novel signal identification algorithm; the NOGB algorithm. NOGB can identify any events that satisfy the three criteria: rare, repeatable and relatively large. Importantly, this algorithm is no longer hindered by either information-losing thresholding or time-consuming iterative optimization. The free parameters are the expected duration of the event, the minimum acceptable amplitude and frequency bandwidth for filtering. NOGB computational time scales linearly with data size, runs in real-time, and adapts to changes in recording fidelity. In addition, however, recordings of electrical biological signals are known to change over hours/days (e.g., due to changes in electrode position ("drift") [old paper showing changes in recorded action potential shape over days] or changes in ion concentrations around the electrode [action potential shape during seizures?]). In particular, the shape of IIS are known to change prior to seizures and following post-seizure sleep, reducing the reliability of signal detection algorithms that assume time-invariance in IIS shape.

Outlier detection has been used previously to identify noise, such as the use of line-length computation to identify signals generated by electrical "ringing" [ref]. Our algorithm uses this method as a preprocessing stage to remove noisy events. Less work has been done, however, to use outliers to separate signals from noise.

The NOGB algorithm was applied to three different datasets to identify clusters of similar signal events across multiple time scales: action potentials in rats (1 msec duration), sharp-wave/ripples in rats and patients (100 msec), and inter-ictal spikes in patients (200 msec). In addition to replicating prior results, we extended Seizure-Related Consolidation (SRC) theory by showing: 1) the necessity of post-seizure sleep for consolidation and 2) that the flexibility offered by the NOGB algorithm provides a novel algorithm for seizure prediction.</Text>
        </Document>
        <Document ID="545B1D65-A806-4983-BBF5-5373608BC798">
            <Title>Methods/interventions</Title>
            <Text>Methods
[Insert text here]</Text>
        </Document>
        <Document ID="8106A8AD-47B0-4690-AFAA-862E41DC5A63">
            <Title>Acknowledgements</Title>
            <Text>Acknowledgements

[Insert text here]</Text>
        </Document>
        <Document ID="EE54C083-F7DD-4781-8BE6-0006326D7E58">
            <Title>Response to Reviewers' Comments</Title>
            <Text>Response to Reviewers’ Comments

We appreciate the detailed comments and suggestions from the reviewers. We have provided our responses below the corresponding comment. 

Reviewer 1
[Insert reviewers’ comments here]

[Authors]

&lt;$fullname&gt;</Text>
        </Document>
        <Document ID="2ACB4616-B602-4EDE-8112-17D7985E3285">
            <Title>Conclusion</Title>
            <Text>Conclusion

[Insert text here]</Text>
        </Document>
        <Document ID="7B8BA890-D211-41AE-89ED-E2EA8715AE06">
            <Title>Table X</Title>
            <Synopsis>After you insert Table caption, you may either make the table in Scrivener, or you may insert it in text-processor (Word etc) after compiling.</Synopsis>
            <Text>Table X: [insert text here]
[insert table here]</Text>
        </Document>
        <Document ID="68E67F95-E40B-49C6-98AB-9FC39CA703CA">
            <Title>To-Do List</Title>
            <Text>	⁃	Uncompleted To-Do
	✓	Completed To-Do</Text>
        </Document>
        <Document ID="5BDD6160-D6D8-4096-94E1-C70A90162259">
            <Title>General</Title>
            <Text>

There are also document templates for Cover letter and Point-by-point response also. 

You will probably need to compile them separately as most journals request that you upload them as separate files.
</Text>
        </Document>
        <Document ID="5B6C8CF5-4372-473E-A90B-0C5D380681D0">
            <Title>Outcome measurements</Title>
            <Text>Outcome measurements
[Insert text here]</Text>
        </Document>
        <Document ID="721F96BD-C185-4068-BFD6-C84B9BE1AC6A">
            <Title>Background and Significance</Title>
            <Text>Background and Significance

Despite variations in the physical mechanisms underlying signal generation (e.g., single neurons and summed field potentials) and physiological recording (e.g.,macroelectrodes and microwires), one invariant of pre-processing remains identifying temporally-bounded events, or “signals” (e.g., action potentials, sharp-wave/ripple complexes (SWR), interictal spikes (IIS), neocortical spindles, sleep-related K-complexes). This differs from identifying temporally unbounded states (e.g., sleep stages, theta oscillations during exploration, “up” or “down” neocortical states).   Signal processing algorithms applied to electrophysiological data have long placed a high priority on both noise reduction and elimination at the start of processing. Historically, this arose both from limited computational power (which emphasized reducing the amount of data to be processed early in the processing stream) and from expensive data storage (which emphasized reducing storage requirements). Technological advances, however, have reduced the importance of these considerations, placing "Big Data" capabilities in the hands of individual researchers. This has allowed for the emergence of algorithms that replace idealized assumptions about data (e.g., Gaussian distributions) with computationally intensive approches that rely solely on the data, but few examples exist where these new capabilities have been utilized for extracellular signal processing.

Extracellular neural signal detection and clustering has continued to rely on classical optimization approaches, such as Maximum Likelihood Estimation, which assume underlying models consisting of ideal, analytic distributions such as a mixture-of-gaussians. Importantly, the field continues to rely on noise elimination as an early processing step, often ignoring the significant amount of information that could be utilized. This is particularly important in the analysis of electrophysiological data, because so much of what is recorded is noise. Consider a system that is recording action potentials from three different neurons that each have an average firing rate of 2 Hz. Given that the duration of an action potential is roughly 1 msec, then 6 msec of action potential waveforms will be recorded per second, leaving 994 msec of noise. The signal constitutes less than 1% of the recorded data, so noise elimination removes over 99% of the acquired data *as a first step* [human neuroprosthetics paper]! This is a significant loss of information, even if it is only noise. This is problematic in situations where the signal itself is known to change with time where there is no clear method to identify noise when the signal itself is changing. This includes common situations such as electrode drift, but also includes more complex situations such as bursts of action potentials with the accompanying decrement of recorded amplitude as the burst progresses and inter-ictal spikes (IIS) in epilepsy that are known to change following successive seizures.

In addition, clustering algorithms have routinely relied on error minimization approaches [Duda and Hart]. These approaches were optimized for the strengths of computers, but are not inherently intuitive to humans, as is shown by the current methods used to teach physicians and neuroscientists to identify events of interest in electroencephalographic (EEG) recordings (i.e., to "read" EEG). Normally, recordings are observed over minutes or even hours, looking for events that share four properties: temporally-restricted, repeatable, rare and realistic. For example, sharp-wave/ripple complexes in rodent recordings are identified as brief (~100 msec), rare (&lt;1 Hz) events that produce a characteristic (i.e., repeatable) sound over audio amplifiers without saturating those amplifiers (i.e., physiologically realistic). Trained observers reject both far more frequent, lower-amplitude background "noise" and far less frequent "artifacts" that often is often so large in amplitude as to be non-physiological (Figure 1). 

Other approaches have been less utilized. One such area is graphical/network methods that utilize connectivity to identify clusters (called "communities" in network analysis [Barabasi]). If the factors that govern connectivity are time-local, then clusters naturally become time-varying and thus les sensitive to time-varying factors such as drift. Can I use the capabilities of Scrivener to help with the algo-epilespy conundrum of the current mx? The main reason for combining the two is the fact that I know, going into my analysis, that the shape of IIS change prior to and following a seizure. This led to the desire for a means of identifying biological signals that did not rely solely on the shape of signals. The insight was the hypothesis that relationships between signals generated by a given source (regardless of changes to the waveform) differ from those generated by noise, which is assumed to come from multiple, overlapping, stochastic sources. 

The Iron Law of Noise: Low count. Small peak. Variable shape. This is as much a cultural or “belief” principle as it is an objective one; people will not accept small, frequent and variable waveforms as signals. 

What kind of “relationships”? This is a conceptual jump. It makes sense to me, because I have already examined the results of the analysis. Why would you build a graph of events and connect them by CC? Is there some evidence from graph theory that such networks can provide meaningful information? Why not use Granger Causality or some other “relatedness” metric? What is special or powerful about graphs? I could add the properties of hubs to the hypothesis? That does seem reasonable: if signals arise from a single generator, then the sample closest to the “true” signal will be central to the distribution of samples; whereas if noise arises from the summation of multiple sources, then no single sample should be more central to multiple centroids.

So, two hypotheses: 1) The Law of Noise: Compared to signal, noise samples are more common, have lower amplitude and are less regular. The latter observation is true, because 2) signals arise from a single generator that will map to a single centroid, while noise arises from multiple, overlapping generators. Even if the observed properties of signal generators change with time (as is known for bursting, or “complex” neurons), they will change in a systematic, repeated fashion. These hypotheses lead to the prediction that graphs of signal relatedness will be more hub-like.

The original goal of this project was to analyze IIS for a multi-year, multi-patient dataset obtained using the NeuroVista intracranial, ambulatory EEG recording system (Cook et al., XXXX). Given that our prior work has shown that seizures alter the shape and synchrony of IIS (Bower et al., 2017), artifact could be introduced into IIS detections algorithms that assume signal stationarity. To diminish this, we sought an algorithm that considered both temporally local signals (to identify similar waveforms) and global signals (to examine persistent changes to IIS shape and synchrony. We evaluated the performance of this algorithm on artificial data, as well as on real-world rodent and human data to reproduce known phenomena. Finally, we applied this algorithm to the NeuroVista dataset to determine whether seizure produce lasting changes to neural circuitry.



</Text>
        </Document>
        <Document ID="40793B08-2A79-42A3-85B4-7B03DFBABEA1">
            <Title>Results</Title>
            <Text>Results

Rat data: 	- AP
	⁃	comparison to manual-cut
	⁃	place cells
	- SWR
	⁃	&lt;other detector?&gt;
	⁃	phase precession

Human data: - AP
	⁃	comparison to manual-cut
	⁃	AP fire more during sleep
	⁃	 - IIS
	⁃	&lt;other detector?&gt;
	⁃	SRC (sleep scoring?)
NeuroVista:	- IIS
				- SRC
</Text>
        </Document>
        <Document ID="7F0F264D-E5E7-4E14-AF5C-6BCF6A076B83">
            <Title>Tables</Title>
        </Document>
        <Document ID="D830C416-BF8F-45E7-9776-E1F76E40A268">
            <Title>Discussion</Title>
            <Text>Discussion

The NOGB 

Frequently, physiological parameters are applied to processed data to select those identified clusters whose parameters match expected values for physiological entities (i.e., to identify those clusters with a physiologically realistic firing rate). NOA reverses this and uses expected physiological ranges to identify clusters from the outset.

Is this any better than a simple threshold detector? How to compare? One advantage is that the identification step produces clusters that could be used in subsequent, standard cluster-joining steps.


</Text>
        </Document>
        <Document ID="99BA1532-14FA-4D27-B980-B8A233C06D4D">
            <Title>Front page</Title>
            <Text>&lt;$Projecttitle&gt;

Running head:
&lt;$abbr_title&gt;

Authors:

[Insert authors here]

Word count: &lt;$wc&gt;</Text>
            <Notes>Populate Project meta-data settings in order to have Title and Running head (or Abbreviated title) automatically generated.
You may also insert appropriate text at the placeholders if you don’t want Scrivener to generate title for you.</Notes>
        </Document>
        <Document ID="02C52771-3FBE-4CE6-8FE5-D9CB75D6624F">
            <Title>Figure legends</Title>
            <Text>Figure Legends
Figure 1: [insert text here]
Figure 2: [insert text here]</Text>
        </Document>
        <Document ID="0F5B4E94-FB6A-474F-B842-12B39748207B">
            <Title>Methods</Title>
            <Text>Methods

Network Parameter Outlier (NPO)

The NPO algorithm consists of two stages (a “local” and a “global” stage), each consisting of several steps. The first, “local” stage processes data In a sliding window: 1.1) Apply spectral filtering to the data, 1.2) Detect all local peaks, regardless of polarity, 1.3) Construct a network where vertices represent each 	peak and edges represent the correlation coefficient between peaks, keeping only those edges whose coefficient magnitude is greater than a user-defined threshold. 1.4) Identify “cliques” of similar vertices using a network clustering algorithm (‘cluster_louvain’ in R, [Blondel et al., 2008]) and persist these clique memberships to a database. The second, “global” stage can be performed either online (when no further detections are found in the sliding window for a given clique) or offline for all cliques once the recording is finished. 2.1) For each clique, reconstruct the complete network for the entire recording duration (called the “global network”). 2.2) Compute network properties. Cliques whose properties differ from that of the most common detections (i.e., "noise") are designated as “signal”. 2.3) Combine cliques to form clusters, either by collecting all cliques labeled as “signal” into one cluster, or by using standard clustering techniques on average clique parameters (e.g., as described below, we used Mahalanobis distances on clique average waveforms).

This algorithm has three, free parameters based on expected physiological properties of events: 1) spectral frequencies, 2) sliding window duration, 3) cross-correlation threshold.

Rodent Data - MSO Model
Rats were treated with Methionine Sulfoximide (MSO), as described previously (XXXX). 

Human Data - ICU
Intracranial EEG were obtained from patients undergoing treatment for medically refractive epilepsy at Yale Hospital, as described previously (XXXX). Patients were implanted with intracranial grid and depth electrodes, along with Behnke-Fried electrodes. Continuous recordings were obtained at 32 kHz. 

Human Data - Ambulatory

Ambulatory, intracranial EEG were obtained from patients over multiple months, as described previously (Cook et al., XXXX).
 </Text>
        </Document>
        <Document ID="2B4F03E1-67CA-455B-B712-1FB85B3E6C5F">
            <Title>Table 1</Title>
            <Synopsis>After you insert Table caption, you may either make the table in Scrivener, or you may insert it in text-processor (Word etc) after compiling.</Synopsis>
            <Text>Table 1: [insert text here]
[insert table here]</Text>
        </Document>
        <Document ID="8E3B8F50-D8BC-40A0-B28B-CD7DBDAC8610">
            <Title>Figure 1</Title>
        </Document>
        <Document ID="8F7E1F42-2CBF-427A-AA23-281D01C278C2">
            <Title>Main content</Title>
        </Document>
        <Document ID="9767792B-1578-4360-AB61-A457F3B3D1D3">
            <Title>References</Title>
            <Text>References

[Leave this empty to use a reference manager like Zotero. Once you create a bibliography in LibreOffice/Word, paste the generated references into this part of the document]</Text>
            <Notes>If you are using EndNote, Zotero, or Mendeley you will need to cut and paste the generated references into this part of the document.  </Notes>
        </Document>
        <Document ID="3DB42624-9799-48E0-BFA1-F0FA26355C95">
            <Title>20062014 Submitted to [journal]</Title>
        </Document>
        <Document ID="B3B274C9-B374-43F7-848F-05083101B7E6">
            <Title>Figures</Title>
        </Document>
        <Document ID="108244DD-4B15-4BBF-85C3-7847D9F45D2C">
            <Title>Patients</Title>
            <Text>METHODS
Patients
[Insert text here]</Text>
        </Document>
        <Document ID="9C178351-9B21-4692-97C3-68FBA6F80D27">
            <Title>Statistical analysis</Title>
            <Text>Statistical analysis
[Insert text here]</Text>
        </Document>
        <Document ID="0F3A8983-6251-42BE-A46F-7C6F03879CC3">
            <Title>Ideas</Title>
        </Document>
    </Documents>
</SearchIndexes>